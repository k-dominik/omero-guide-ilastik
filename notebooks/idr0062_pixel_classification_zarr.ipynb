{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Zarr Image with labels from a public S3 repository, analyze using ilastik and compare results.\n",
    "The notebook shows how to load an IDR image converted into a Zarr file with labels.\n",
    "\n",
    "The image is referenced in the paper \"NesSys: a novel method for accurate nuclear segmentation in 3D\" published August 2019 in PLOS Biology: https://doi.org/10.1371/journal.pbio.3000388 and can be viewed online in the [Image Data Resource](https://idr.openmicroscopy.org/webclient/?show=image-6001247).\n",
    "\n",
    "This original image was converted into the Zarr format. The analysis results produced by the paper authors were converted into labels and linked to the Zarr file which was placed into a public S3 repository.\n",
    "\n",
    "In this notebook, the converted Zarr file is then loaded together with the labels from the S3 storage and analyzed using [ilastik](https://ilastik.github.io/). The ilastik analysis produces a probability map based on pixel classification. These probability maps are then viewed side-by-side with the original segmentations produced by the authors of the papers obtained via the loaded labels.\n",
    "\n",
    "If you run this notebook with different images or ilastik projects, the dimension might need to be adjusted depending on the ilastik project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insert required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy\n",
    "import zarr\n",
    "import dask.array as da\n",
    "from dask.diagnostics import ProgressBar\n",
    "\n",
    "from ilastik import app\n",
    "from ilastik.applets.dataSelection.opDataSelection import PreloadedArrayDatasetInfo\n",
    "import vigra\n",
    "\n",
    "# package for 3d visualization\n",
    "from itkwidgets import compare, view"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enter the image ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_id = 6001247"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper method to load an Image as 5D-numpy array from S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_from_s3(id, resolution='0'):\n",
    "    endpoint_url = 'https://uk1s3.embassy.ebi.ac.uk/'\n",
    "    root = 'idr/zarr/v0.1/%s.zarr/%s/' % (id, resolution)\n",
    "    # data.shape is (t, c, z, y, x) by convention\n",
    "    with ProgressBar():\n",
    "        return numpy.asarray(da.from_zarr(endpoint_url + root))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper method to load the labels linked to the Image from S3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_labels_from_s3(id, resolution='0'):\n",
    "    endpoint_url = 'https://uk1s3.embassy.ebi.ac.uk/'\n",
    "    root = 'idr/zarr/v0.1/%s.zarr/labels/%s/' % (id, resolution)\n",
    "    return da.from_zarr(endpoint_url + root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the image data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed | 3.30 sms\n",
      "CPU times: user 1.45 s, sys: 344 ms, total: 1.79 s\n",
      "Wall time: 3.54 s\n"
     ]
    }
   ],
   "source": [
    "%time input_data = load_from_s3(image_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = load_labels_from_s3(image_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store the original image channels for later comparison with probability map generated by ilastik."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_channel = input_data[0, 0, :, : ,:]\n",
    "second_channel = input_data[0, 1, :, : ,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load each image as a 5D-numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2, 257, 210, 253)\n",
      "(1, 257, 210, 253, 2)\n"
     ]
    }
   ],
   "source": [
    "# Re-order the array tczyx -> tzyxc\n",
    "print(input_data.shape)\n",
    "input_data = input_data.swapaxes(1, 2).swapaxes(2, 3).swapaxes(3, 4)\n",
    "print(input_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze data\n",
    "We are now running an ilastik pixel classication pipeline on the data.\n",
    "Running the analysis could take a few minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO ilastik.app: Using tiktorch executable: ['/Users/jmarie/opt/anaconda3/envs/imaging_course_ilastik/bin/python', '-m', 'tiktorch.server']\n",
      "INFO ilastik.app: config file location: <none>\n",
      "INFO ilastik.app: Starting ilastik from /Users/jmarie/opt/anaconda3/envs/imaging_course_ilastik/lib/python3.9\n",
      "Starting ilastik from /Users/jmarie/opt/anaconda3/envs/imaging_course_ilastik/lib/python3.9\n",
      "INFO ilastik.app: Resetting lazyflow thread pool with 2 threads.\n",
      "INFO ilastik.app: Configuring lazyflow RAM limit to 2.0GiB\n",
      "INFO lazyflow.utility.memory: Available memory set to 2.0GiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING 2024-10-29 22:14:58,014 opConservationTracking 78237 8664184320 Could not find any ILP solver\n",
      "WARNING 2024-10-29 22:14:58,025 opStructuredTracking 78237 8664184320 Could not find any ILP solver\n",
      "WARNING 2024-10-29 22:14:58,027 structuredTrackingWorkflow 78237 8664184320 Could not find any learning solver. Tracking will use flow-based solver (DPCT). Learning for tracking will be disabled!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO ilastik.shell.projectManager: Opening Project: ./pipelines/pixel-class-133.ilp\n",
      "running ilastik using ./pipelines/pixel-class-133.ilp\n",
      "DEBUG lazyflow.operators.classifierOperators.OpBaseClassifierPredict: classifier changed, setting dirty\n",
      "DEBUG lazyflow.operators.classifierOperators.OpBaseClassifierPredict: classifier changed, setting dirty\n",
      "DEBUG lazyflow.operators.classifierOperators.OpBaseClassifierPredict: classifier changed, setting dirty\n",
      "DEBUG lazyflow.operators.classifierOperators.OpBaseClassifierPredict: classifier changed, setting dirty\n",
      "INFO ilastik.applets.batchProcessing.batchProcessingApplet: Exporting to in-memory array.\n",
      "INFO lazyflow.utility.bigRequestStreamer: Estimated RAM usage per pixel is 504.0B * safety factor (2.0)\n",
      "INFO lazyflow.utility.bigRequestStreamer: determining blockshape assuming available_ram is 1.5GiB, split between 2 threads\n",
      "INFO lazyflow.utility.bigRequestStreamer: Chose blockshape: (1, 92, 92, 92, 2)\n",
      "INFO lazyflow.utility.bigRequestStreamer: Estimated RAM usage per block is 748.6MiB\n",
      "DEBUG lazyflow.operators.classifierOperators: Features took 3.476479 seconds. Prediction took 1.190587 seconds. Subregion: start '[0, 0, 0, 0]' stop '[92, 92, 92, 2]'\n",
      "DEBUG lazyflow.operators.classifierOperators: Features took 6.421156 seconds. Prediction took 1.332864 seconds. Subregion: start '[0, 0, 92, 0]' stop '[92, 92, 184, 2]'\n",
      "DEBUG lazyflow.operators.classifierOperators: Features took 4.186462 seconds. Prediction took 0.983758 seconds. Subregion: start '[0, 0, 184, 0]' stop '[92, 92, 253, 2]'\n",
      "DEBUG lazyflow.operators.classifierOperators: Features took 4.411571 seconds. Prediction took 1.269056 seconds. Subregion: start '[0, 92, 0, 0]' stop '[92, 184, 92, 2]'\n",
      "DEBUG lazyflow.operators.classifierOperators: Features took 5.697669 seconds. Prediction took 1.368494 seconds. Subregion: start '[0, 92, 92, 0]' stop '[92, 184, 184, 2]'\n",
      "DEBUG lazyflow.operators.classifierOperators: Features took 4.847656 seconds. Prediction took 1.080542 seconds. Subregion: start '[0, 92, 184, 0]' stop '[92, 184, 253, 2]'\n",
      "DEBUG lazyflow.operators.classifierOperators: Features took 2.522057 seconds. Prediction took 0.517758 seconds. Subregion: start '[0, 184, 0, 0]' stop '[92, 210, 92, 2]'\n",
      "DEBUG lazyflow.operators.classifierOperators: Features took 1.601923 seconds. Prediction took 0.36879 seconds. Subregion: start '[0, 184, 92, 0]' stop '[92, 210, 184, 2]'\n",
      "DEBUG lazyflow.operators.classifierOperators: Features took 1.5964230000000001 seconds. Prediction took 0.434181 seconds. Subregion: start '[0, 184, 184, 0]' stop '[92, 210, 253, 2]'\n",
      "DEBUG lazyflow.operators.classifierOperators: Features took 3.7624880000000003 seconds. Prediction took 1.29891 seconds. Subregion: start '[92, 0, 0, 0]' stop '[184, 92, 92, 2]'\n",
      "DEBUG lazyflow.operators.classifierOperators: Features took 6.273576 seconds. Prediction took 1.459899 seconds. Subregion: start '[92, 0, 92, 0]' stop '[184, 92, 184, 2]'\n",
      "DEBUG lazyflow.operators.classifierOperators: Features took 4.46357 seconds. Prediction took 1.061711 seconds. Subregion: start '[92, 0, 184, 0]' stop '[184, 92, 253, 2]'\n",
      "DEBUG lazyflow.operators.classifierOperators: Features took 4.965694 seconds. Prediction took 1.765015 seconds. Subregion: start '[92, 92, 0, 0]' stop '[184, 184, 92, 2]'\n",
      "DEBUG lazyflow.operators.classifierOperators: Features took 6.04428 seconds. Prediction took 1.259896 seconds. Subregion: start '[92, 92, 92, 0]' stop '[184, 184, 184, 2]'\n",
      "DEBUG lazyflow.operators.classifierOperators: Features took 4.414871 seconds. Prediction took 0.950784 seconds. Subregion: start '[92, 92, 184, 0]' stop '[184, 184, 253, 2]'\n",
      "DEBUG lazyflow.operators.classifierOperators: Features took 2.627998 seconds. Prediction took 0.601516 seconds. Subregion: start '[92, 184, 0, 0]' stop '[184, 210, 92, 2]'\n",
      "DEBUG lazyflow.operators.classifierOperators: Features took 1.815021 seconds. Prediction took 0.342588 seconds. Subregion: start '[92, 184, 92, 0]' stop '[184, 210, 184, 2]'\n",
      "DEBUG lazyflow.operators.classifierOperators: Features took 1.684369 seconds. Prediction took 0.4176 seconds. Subregion: start '[92, 184, 184, 0]' stop '[184, 210, 253, 2]'\n",
      "DEBUG lazyflow.operators.classifierOperators: Features took 3.119972 seconds. Prediction took 1.008572 seconds. Subregion: start '[184, 0, 0, 0]' stop '[257, 92, 92, 2]'\n",
      "DEBUG lazyflow.operators.classifierOperators: Features took 4.783307 seconds. Prediction took 1.191714 seconds. Subregion: start '[184, 0, 92, 0]' stop '[257, 92, 184, 2]'\n",
      "DEBUG lazyflow.operators.classifierOperators: Features took 3.726687 seconds. Prediction took 0.77642 seconds. Subregion: start '[184, 0, 184, 0]' stop '[257, 92, 253, 2]'\n",
      "DEBUG lazyflow.operators.classifierOperators: Features took 3.676097 seconds. Prediction took 1.055323 seconds. Subregion: start '[184, 92, 0, 0]' stop '[257, 184, 92, 2]'\n",
      "DEBUG lazyflow.operators.classifierOperators: Features took 4.669566 seconds. Prediction took 1.014455 seconds. Subregion: start '[184, 92, 92, 0]' stop '[257, 184, 184, 2]'\n",
      "DEBUG lazyflow.operators.classifierOperators: Features took 3.781196 seconds. Prediction took 0.756856 seconds. Subregion: start '[184, 92, 184, 0]' stop '[257, 184, 253, 2]'\n",
      "DEBUG lazyflow.operators.classifierOperators: Features took 2.031109 seconds. Prediction took 0.507486 seconds. Subregion: start '[184, 184, 0, 0]' stop '[257, 210, 92, 2]'\n",
      "DEBUG lazyflow.operators.classifierOperators: Features took 1.5877970000000001 seconds. Prediction took 0.293618 seconds. Subregion: start '[184, 184, 92, 0]' stop '[257, 210, 184, 2]'\n",
      "DEBUG lazyflow.operators.classifierOperators: Features took 1.387049 seconds. Prediction took 0.204505 seconds. Subregion: start '[184, 184, 184, 0]' stop '[257, 210, 253, 2]'\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# Load the model linked to the image\n",
    "model_file = \"./pipelines/pixel-class-133.ilp\"\n",
    "\n",
    "\n",
    "# Prepare ilastik\n",
    "os.environ[\"LAZYFLOW_THREADS\"] = \"2\"\n",
    "os.environ[\"LAZYFLOW_TOTAL_RAM_MB\"] = \"2000\"\n",
    "args = app.parse_args([])\n",
    "args.headless = True\n",
    "args.project = model_file\n",
    "shell = app.main(args)\n",
    "\n",
    "print('running ilastik using %s' % model_file)\n",
    "role_data_dict = [ {\"Raw Data\": PreloadedArrayDatasetInfo(preloaded_array=input_data, axistags=vigra.defaultAxistags(\"tzyxc\"))}]\n",
    "predictions = shell.workflow.batchProcessingApplet.run_export(role_data_dict, export_to_array=True)\n",
    "for data in predictions:\n",
    "    # Re-organise array from tzyxc to tczyx order\n",
    "    data = data.swapaxes(4, 3).swapaxes(3, 2).swapaxes(2, 1)\n",
    "    data_viewer = data[:, 0, 0, :, :]\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Compare raw data with the ilastik result.\n",
    "View the first channel of the original image (left) and the probability map created by pixel classification module of ilastik (right) side-by-side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd9e3849a8744b2f9241f80900d641f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "AppLayout(children=(HBox(children=(Label(value='Link:'), Checkbox(value=False, description='cmap'), Checkbox(v…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "compare(first_channel, data[0, 0, :, :, :], shadow=False, gradient_opacity=0.2, ui_collapsed=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Compare](images/ilastik_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare the original analysis result with the ilastik result.\n",
    "\n",
    "On the left, the labels loaded from S3 representing the original analysis by the authors of the paper. On the rigth, the probability maps from the pixel classification module of ilastik.\n",
    "\n",
    "The first 2 z-planes do not have labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b9a166327ef4484811c3138a984f643",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "AppLayout(children=(HBox(children=(Label(value='Link:'), Checkbox(value=False, description='cmap'), Checkbox(v…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "compare(labels[0, 0, 2:, :, :], data[0, 0, 2:, :, :], shadow=False, gradient_opacity=0.2, ui_collapsed=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Compare_original](images/ilastik_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overlay the original analysis result and the ilastik result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82275943d0de46929a3f1ba95beb6682",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Viewer(geometries=[], gradient_opacity=0.5, interpolation=False, label_image_blend=0.8, label_image_names=[(0,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "names = [(0, 'labels'), (1, 'Pixels Classification')]\n",
    "viewer = view(labels[0, 0, 2:, :, :],\n",
    "              label_image=data[0, 0, 2:, :, :],\n",
    "              label_image_names=names,\n",
    "              label_image_blend=0.8,\n",
    "              gradient_opacity=0.5,\n",
    "              slicing_planes=False)\n",
    "viewer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Overlay](images/ilastik_3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### License (BSD 2-Clause)\n",
    "Copyright (C) 2019-2024 University of Dundee. All Rights Reserved.\n",
    "\n",
    "Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:\n",
    "\n",
    "Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.\n",
    "Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.\n",
    "THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "imaging_course_ilastik",
   "language": "python",
   "name": "imaging_course_ilastik"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
